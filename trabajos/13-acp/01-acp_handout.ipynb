{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\r\n", "# Trabajo de reducción de dimensión con componentes principales\r\n", "## Introducción\r\n", "En este trabajo, calcularemos los componentes principales asociados a un conjunto de fotos de caras, (provienen del sitio web [\"Labeled Faces in the Wild\"](http://vis-www.cs.umass.edu/lfw/), un conjunto de datos diseñados para testear algoritmos de reconocimientos de caras. \r\n", "\r\n", "Empezamos por cargar los módulos que solemos necesitar"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\r\n", "\r\n", "## Cargamos los datos.\r\n", "El fichero que contiene los datos es faces.csv que se puede descargar del Aula Virtual y guardar en la carpeta data.\r\n", "Contiene 5000 filas y 1024 columnas. Cada fila corresponde a una imagen de 32 x 32 pixeles. Cada columna corresponde a la intensidad de gris de un pixel.\r\n", "\r\n", "Los datos están disponibles en `scikit-learn` usando la función `fetch_lfw_people`. Siguiendo el ejemplo en https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py, "]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_lfw_people\r\n", "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\r\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hemos especificado que queremos sólo las imágenes de personas para las que hay como mínimo 70 datos (imágenes), y hemos realizado un cambio de tamaño de cada imagen. El objeto `lfw_people` tiene varios atributos interesantes: \r\n", "- `data` que es un `np.ndarray` que contiene una fila por imagen, \r\n", "- `images` que es un `np.ndarray` con tres dimensiones: la primera corresponde al número de la imagen, la segunda y tercera a la altura y anchura de cada imagen.\r\n", "- `target` son las etiquetas (números enteros) de personas\r\n", "- `target_names` son los nombres de las personas correspondiente a cada etiqueta.\r\n", "\r\n", "Crear los arrays `X` que contenga las características, `y` que contenga las etiquetas, así como `imagenes` que contenga el array de imágenes.\r\n", "\r\n", "Cuántos datos contiene el conjunto, de cuántos píxeles es cada imagen, cuántas personas están representadas, quienes son y con qué frecuencia aparecen en el conjunto cada uno de ellos?"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos a representar la primera imagen, por ejemplo, usando el mismo código que usamos para representar los dígitos en la práctica anterior, pero ahora usamos el colormap \"gray\"."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Y ahora, representamos 100 al azar, (he usado aquí la semilla 314)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reducción de la dimensión con componentes principales.\r\n", "\r\n", "En el conjunto inicial tenemos 1024 variables, vamos a explorar la reducción de dimensión usando componentes principales.\r\n", "\r\n", "### Obtención de los componentes principales.\r\n", "Podemos usar la clase `PCA` del submódulo `decomposition`. Admite el parámetro `n_components` que indica con cuántos componentes nos queremos quedar. Si no especificamos nada, calcula todos los componentes. Se trata de un transformador, después de instanciarlo en un objeto llamado `acp`, usando todos los componentes, y ajustarlo calculad las coordenadas de cada imagen en cada componente principal usando `transform`. \r\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cuál es la dimensión de `Z`? Podemos obtener las varianzas de cada componente con el atributo `explained_variance_` de `acp`. Cuáles son los tres primeros auto-valores de la matriz de covarianza de `X`?"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Usando el atributo `explained_variance_ratio_`, obtenemos la proporción de varianza explicada por cada componente. Realizad la gráfica de la proporción de varianza explicada acumulada."]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Qué proprición de varianza explicada se alcanza con 150 componentes?"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reducción a 150 componentes.\r\n", "Visto la evolución de la proporción de varianza explicada, vamos a quedarnos con 150 componentes. Para ello, podemos especificar en el momento de instanciar `PCA` el parámetro `n_components`. Repetir el análisis específicando directamente 150 componentes, creando la matriz `Z` de puntuaciones de cada imagen en los 150 componentes."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos obtener los coeficientes que definen cada componente usando el atributo `components_`. Almacena los componentes de manera horizontal, el primer componente, por ejemplo, es la primera fila de `components_`."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["acp.components_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cúal es el pixel que tiene mayor peso (en valor absoluto) en el primer componente? y en el segundo? "]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos representar los pesos de cada pixel en el primer componente en forma de una imagen, donde la intensidad de gris es proporcional al peso de este pixel en PC1."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Representad estos pesos para las seis primeras componentes"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Representad las 5 imágenes del conjunto que más puntúan en el primer componente y las cinco que menos puntúan en este componente. Consejo: podéis usar `argsort` de `numpy`."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Realizad la misma representación para el segundo componente:"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reconstrucción de las imágenes después de la reducción de dimensión\r\n", "\r\n", "`Z` es la matriz de coordenadas de cada imagen en las 150 primeras componentes principales. Si aplicamos al transformador `acp` el método `inverse_transform` pasándole como argumento `Z`, lo que hacemos es completar 0 todos los componentes que faltan y deshacer el cambio de sistema de coordenadas, de manera que volvemos a situarnos en el sistema de intensidad de grises de los píxeles. \r\n"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Repetid la representación si sólo nos quedamos con 20 componentes"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# Completar aquí\r\n", "\n", "# --------------------\n"]}], "metadata": {"interpreter": {"hash": "ca20825bcd0f0eb674939d8509f28a56a9bde324fe3924544b517a227547a10d"}, "kernelspec": {"display_name": "Python 3.7.9 64-bit ('base': conda)", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.9"}, "orig_nbformat": 2}, "nbformat": 4, "nbformat_minor": 2}
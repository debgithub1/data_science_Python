{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Regularización para regresión y clasificación\n", "\n", "## Regresión regularizada\n", "Para ilustrar la regularización usando Ridge y Lasso, vamos a ajustar estos algoritmos a los datos del fichero `datos_regularizacion.csv` disponible en el aula virtual.\n", "\n", "Cargad los datos en un dataframe llamado `datos`.\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n", "datos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Llevad a cabo la representación gráfica del conjunto"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ajustad una regresión lineal usando términos polinomiales de hasta grado 10. Después de incluir las características correspondientes a los términos de grado 10, llevad a cabo la estanderización de las características. \n", "Representad la curva ajustada en la gráfica anterior."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ajuste de una Ridge regression con `alpha=1`\n", "Usando la clase `Ridge` del submódulo `linear_model`, aplicad a los datos una regresión ridge con `alpha=1` usando, al igual que en el apartado anterior, términos polinomiales de grado 10.\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Variamos `alpha` \n", "Representad los ajustes correspondientes a `alpha=0`, `alpha=0.00001`, `alpha=1` en la misma gráfica.\n", "> Consejo: podéis usar un bucle sobre los valores de `alpha`, usando el método `set_params` que se puede aplicar a un estimador para cambiar algunos de sus parámetros (en este caso `alpha`)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Clasificación regularizada: ejemplo con el conjunto MNIST\n", "MNIST es un conjunto de datos muy clásico en machine learning que consiste en imágenes de dígitos escritos a mano en sobres. Las imágenes tienen una resolución de 28 por 28 píxeles, por lo que cada imagen tiene 784 características, cada característica corresponde a la intensidad de gris del pixel correspondiente, va desde 0 (blanco) a 255 (negro).\n", "\n", "MNIST está disponible para descargar desde `sklearn`, pero vamos a cargar una versión reducida con 10000 imágenes, el fichero se llama `mnist_784.10000.csv` y está disponible en el aula virtual. Usad el parámetro `dtype` en `read_csv` para especificar que la columna `y` es de tipo `str`."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Completar aquí: cargar los datos en un conjunto mnist\n", "\n", "# --------------------\n", "mnist"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Crear la `Series` `y` el `DataFrame` `X` "]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n", "print(f'Tamaño de X: {X.shape}, tamaño de y {y.shape}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Si queréis trabajar con el conjunto completo, se puede descargar directamente desde `sklearn`, tened en cuenta que los tiempos de ejecución son más largos."]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# Si queréis trabajar con el conjunto completo:\n", "# from sklearn.datasets import fetch_openml\n", "# mnist = fetch_openml('mnist_784', version=1)\n", "# # el resultado es un diccionario, dos claves importantes son data y target\n", "# X, y = mnist['data'], mnist['target']\n", "# print(f'Tamaño de X: {X.shape}, tamaño de y {y.shape}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos visualizar una de las imágenes:"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# nada que completar\n", "from matplotlib import cm\n", "fig, ax = plt.subplots()\n", "imagen = X.iloc[3600,:].values.reshape(28, 28)\n", "ax.imshow(\n", "    imagen,\n", "    cmap=cm.binary,\n", "    interpolation='nearest'\n", ")\n", "ax.axis('off');\n", "print(f'Etiqueta: {y.iloc[3600]}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Representamos 10 imágenes escogidas al azar de cada etiqueta:"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# Nada que completar\n", "from numpy.random import default_rng\n", "rng = default_rng(314)\n", "fig, axes= plt.subplots(10, 10, figsize=(10,10))\n", "for i in range(10):\n", "    indexes = rng.choice(X[y==str(i)].index, replace=False,size=10)\n", "    for j in range(10):\n", "        imagen = X.loc[indexes[j],:].values.reshape(28, 28)\n", "        axes[i, j].imshow(\n", "            imagen,\n", "            cmap=cm.binary,\n", "            interpolation='nearest'\n", "        )\n", "        axes[i , j].axis('off');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Separación conjunto de aprendizaje, conjunto de test\n", "Lo primero que vamos a hacer es apartar un subconjunto de test.  Vamos a usar para ello `StratifiedShuffleSplit` del submódulo `model_selection`, que hace una separación (split) aleatoria, pero de manera que las dos partes generadas contengan proporciones parecidas de los valores de `y`. "]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import StratifiedShuffleSplit\n", "# Empezamos por crear el objeto que realizará el split\n", "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=314)\n", "for train_index, test_index in split.split(X, y):\n", "    X_train, y_train = X.loc[train_index].values, y.loc[train_index].values\n", "    X_test, y_test = X.loc[test_index].values, y.loc[test_index].values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comprobad que se ha respetado la proporción de las etiquetas tanto en el conjunto train como en el conjunto test."]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Aplicación de la regresión logística con penalización l2\n", "> No se trata de un problema de clasificación binario sino multiclases (10). El algoritmo `LogisticRegression` aplica automáticamente la estrategia de \"One Versus all\"\n", "\n", "Siguiendo lo realizado en la práctica anterior, realizad sobre el conjunto de aprendizaje la predicción con penalización l2, usando el defecto de `C=1`, a través de validación cruzada. Antes de aplicar la regresión logística, estanderizad las características.\n", "Guardad el resultado de las predicciones en `y_train_pred`."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n", "y_train_pred[:15]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Construid la matriz de confusión y asignadla a un objeto llamado `matriz_confusion`."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n", "matriz_confusion"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Obtened la tasa de acierto del algoritmo. Para ello, podeís usar `numpy.trace` para obtener la traza de una matriz y por otra parte, compararlo con el resultado del método `accuracy_score` del súbmodulo `metrics`."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos a calcular ahora la precisión. Al tratarse de un clasificación multiclases, lo que calculamos es la precisión para cada clase y hacemos el promedio de los 10 valores obtenidos.\n", "Usando la matriz de confusión, calculad la precisión para cada clase (de 0 a 9). \n", "> Consejo: podéis usar el método `diagonal` aplicado a un array numpy para extraer los elementos diagonales y  `np.divide` para hacer la división de dos arrays, elemento a elemento"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculad la precision promedio sobre clases.\n"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Repetid estos cálculos para conseguir la sensibilidad promedio sobre clases"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En realidad, podríamos haber calculado directamente estos valores promedios usando `precision_score` y `recall_score` del submódulo `metrics`, con el parámetro `average=\"macro\"`"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculad la precisión y la sensibilidad promedio que obtenemos aplicando sobre el conjunto de test el modelo entrenado con el conjunto de aprendizaje."]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Búsqueda del mejor valor de `C` para la regresión logística regularizada.\n", "Usad `GridSearchCV` para decidir qué valor de `C` fijar entre las siguientes posibilidades:\n", "0.005, 0.01, 0.05, 0.1, 1.\n", "> Recordad que para el problema de clasificación, el parámetro `scoring` debe tomar el valor 'accuracy'."]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cuál es el valor de `C` que corresponde al mejor modelo? Corresponde a más o menos regularización que la opción por defecto de `LogisticRegression`?\n", "\n", "Calculad, para el mejor modelo, la precisión promedio y la sensibilidad promedio sobre las clases, usando para empezar el conjunto de aprendizaje y a continuación el conjunto de test\n"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["# Completar aquí\n", "\n", "# --------------------\n", "\n"]}], "metadata": {"interpreter": {"hash": "ca20825bcd0f0eb674939d8509f28a56a9bde324fe3924544b517a227547a10d"}, "kernelspec": {"display_name": "Python 3.7.9 64-bit ('base': conda)", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.2"}, "orig_nbformat": 2}, "nbformat": 4, "nbformat_minor": 2}